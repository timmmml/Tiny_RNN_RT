{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ded5ae",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "This module will guide you through some minimal steps in looking at and manipulating existing modules in the package. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "500b5c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def run():\n",
    "    path = Path.cwd()\n",
    "    while len(path.name) and path.name != 'codes':\n",
    "        path = path.parent\n",
    "\n",
    "    if len(path.name):\n",
    "        os.chdir(path)\n",
    "    else:\n",
    "        raise ValueError('Cannot find the root directory of the project.')\n",
    "\n",
    "run()\n",
    "from path_settings import *\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "from agents import Agent\n",
    "from tasks import akam_tasks as ts\n",
    "from utils import *  # get_current_file_name, goto_root_dir\n",
    "import pprint\n",
    "import CustomMapper.CustomMapper as c\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import config as co\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from agents.DynamicSystems import ISNNet\n",
    "from agents.ComplexAgent import DynamicAgent\n",
    "import copy\n",
    "import plotly.express as px\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4, depth = 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f3e1d",
   "metadata": {},
   "source": [
    "# Step 1: simulate some datasets\n",
    "\n",
    "In my setup, I organize datasets in the CustomMapper data type. The datatype basically links a cognitive model with an RT model, setting up parameters and stuff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a411d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating cog agent MB0s with params [0.5, 5.0]\n",
      "n_blocks 1000 n_trials 100 sim_seed 0 sim_exp_name simulated_Akam_RTS additional_name \n",
      "Simulating cog agent LS0 with params [0.1, 5.0]\n",
      "n_blocks 1000 n_trials 100 sim_seed 0 sim_exp_name simulated_Akam_RTS additional_name \n",
      "Simulating cog agent MB0 with params [0.5, 5.0]\n",
      "n_blocks 1000 n_trials 100 sim_seed 0 sim_exp_name simulated_Akam_RTS additional_name \n",
      "Simulating cog agent MB1 with params [0.5, 0.5, 5.0]\n",
      "n_blocks 1000 n_trials 100 sim_seed 0 sim_exp_name simulated_Akam_RTS additional_name \n"
     ]
    }
   ],
   "source": [
    "# Define agent and task. \n",
    "# This is based on Ji-an's codes. The end product is consist of an array of stims, choices, and rewards\n",
    "# it will automatically save the data in the folder specified in the config file. \n",
    "\n",
    "tasks = {\n",
    "    # \"PRL\": ts.Two_step(com_prob=1),  # common transition always happens\n",
    "    # \"RTS\": ts.Two_step(), # reversal two-stage, probabilistic transition \n",
    "    # \"NTS\": ts.Two_step(rew_gen=\"trans_rev\"), \n",
    "    \"walk\": ts.Two_step(rew_gen=\"walks\"),\n",
    "}\n",
    "\n",
    "N_blocks = 1000\n",
    "N_trials = 100\n",
    "device = \"cpu\"\n",
    "seed = 0\n",
    "agents = {}\n",
    "config = {}\n",
    "cog_types = [\"MB0s\", \"LS0\", \"MB0\", \"MB1\"]\n",
    "\n",
    "\n",
    "for cog_type in cog_types:\n",
    "    cog_config = co.sim_config_from_inputs(False, \n",
    "                                        agent_type=\"RTSCog\", # calls a cognitive agent for the reduced two step task. \n",
    "                                        cog_type=cog_type, # agent type \n",
    "                                        device=device, \n",
    "                                        seed=seed,\n",
    "                                        num_blocks=N_blocks,\n",
    "                                        num_trials=N_trials,\n",
    "                                        exp_folder=0)\n",
    "    config[f'walks_{cog_type}'] = cog_config\n",
    "    agents[f'walks_{cog_type}'] = Agent(cog_config['agent_type'], config = cog_config)\n",
    "\n",
    "for cog_type in cog_types: \n",
    "    agents[f'walks_{cog_type}'].simulate(tasks[\"walk\"], config[f'walks_{cog_type}'], save = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e9292",
   "metadata": {},
   "source": [
    "Now, onto defining the CustomMapper. \n",
    "\n",
    "It was designed to hold everything, from the cognitive datasets to the RT models, and to your RNN model. However I only used it in the first iterations in the project (later I just defined new trainers and datasets). You are welcome to modify the codes a bit to clean everything up and make everything uniform and tidy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a547d20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 0\n",
      "Block 1\n",
      "Block 2\n",
      "Block 3\n",
      "Block 4\n",
      "Block 5\n",
      "Block 6\n",
      "Block 7\n",
      "Block 8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMB0s\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\u001b[38;5;66;03m#, \"LS0\", \"MB0\", \"MB1\"]:\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     RTRNN_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcog_data\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m SIM_SAVE_PATH \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimulated_Akam_RTS\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_seed0.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 53\u001b[0m     experiment \u001b[38;5;241m=\u001b[39m \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCustomMapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRTRNN_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     experiment\u001b[38;5;241m.\u001b[39mrt_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRELOAD\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(experiment, \u001b[38;5;28mopen\u001b[39m(DATA_PATH\u001b[38;5;241m/\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_1.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/projects/Tiny_RNN_RT/codes/CustomMapper/CustomMapper.py:41\u001b[0m, in \u001b[0;36mCustomMapper.__init__\u001b[0;34m(self, configs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mredo_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrt_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_RT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cog_data_frame()\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/Tiny_RNN_RT/codes/CustomMapper/CustomMapper.py:126\u001b[0m, in \u001b[0;36mCustomMapper.add_RT\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    123\u001b[0m score_block \u001b[38;5;241m=\u001b[39m score_blocks[i]\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(score_block)):\n\u001b[1;32m    125\u001b[0m     solution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrt_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m--> 126\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrength_A\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_block\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrength_B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_block\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# Mapping index 0 (in scores) to Lower, 1 to Higher\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     rts \u001b[38;5;241m=\u001b[39m [solution\u001b[38;5;241m.\u001b[39mchoice_lower, solution\u001b[38;5;241m.\u001b[39mchoice_upper]\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.12/site-packages/paranoid/decorators.py:115\u001b[0m, in \u001b[0;36m_wrap.<locals>._decorated\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decorated\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# Skip verification if paranoid is disabled.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Settings\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, function\u001b[38;5;241m=\u001b[39mfunc) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# We only run this function once for performance reasons, and\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# then pass it as an argument to each check function.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     sig \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mSignature\u001b[38;5;241m.\u001b[39mfrom_callable(func)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.12/site-packages/pyddm/solution.py:524\u001b[0m, in \u001b[0;36mSolution.sample\u001b[0;34m(self, k, seed)\u001b[0m\n\u001b[1;32m    522\u001b[0m     _logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistribution sums to \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m rather than 1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m np\u001b[38;5;241m.\u001b[39msum(combined_probs))\n\u001b[1;32m    523\u001b[0m     _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_parameters)\n\u001b[0;32m--> 524\u001b[0m samp \u001b[38;5;241m=\u001b[39m \u001b[43mrng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_domain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombined_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m undecided \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(samp\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    526\u001b[0m samp \u001b[38;5;241m=\u001b[39m samp[samp \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m# Remove undecided trials\u001b[39;00m\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:982\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.12/site-packages/numpy/core/fromnumeric.py:2974\u001b[0m, in \u001b[0;36m_prod_dispatcher\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2960\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2961\u001b[0m \u001b[38;5;124;03m    Return the minimum of an array or minimum along an axis.\u001b[39;00m\n\u001b[1;32m   2962\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2968\u001b[0m \u001b[38;5;124;03m    ndarray.min : equivalent method\u001b[39;00m\n\u001b[1;32m   2969\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapreduction(a, np\u001b[38;5;241m.\u001b[39mminimum, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out,\n\u001b[1;32m   2971\u001b[0m                           keepdims\u001b[38;5;241m=\u001b[39mkeepdims, initial\u001b[38;5;241m=\u001b[39minitial, where\u001b[38;5;241m=\u001b[39mwhere)\n\u001b[0;32m-> 2974\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prod_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2975\u001b[0m                      initial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2976\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[1;32m   2979\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_prod_dispatcher)\n\u001b[1;32m   2980\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprod\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2981\u001b[0m          initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RTRNN_config = {\n",
    "    \"task\": \"PRL_Bartolo\", \n",
    "    \"dt\": 0.02, # 0.02s time step, as in Jaffe et al. This is also used in the DDM simulation of RTs. \n",
    "    \"T\": 200, # 1s upper for RT for the DDM \n",
    "    \"cog_data\": SIM_SAVE_PATH / 'simulated_Akam_RTS' / 'LS0_seed0.pkl',\n",
    "    \"bias\": 0.01, \n",
    "    \"ndt_s\": 0.01, \n",
    "    \"ndt_mu\": 0.1, \n",
    "    \"driftscale\": 2, \n",
    "    \"redo_choices\": False,\n",
    "    \"trainer_type\": \"RTRNNTrainer\",\n",
    "    \"model_specs\": {\n",
    "        \"model_name\": \"RTRNN\", \n",
    "        \"model_path\": \"Network_models.RTRNN\",\n",
    "        \"model_params\":{ # model setup params, NOTE that recurrence_per_trial is how many RNN steps per trial\n",
    "            \"batch_size\": 20, \"input_size\": 6, \"output_size\": 2, \"hidden_size\": 16, \"recurrence_per_trial\": 2,\n",
    "            \"cell_type\":\"GRU\", \"trial_output_hidden\": 0, \"trial_output_hidden_size\": [], # if want hidden output layers (deep output, then give a list)\n",
    "            \"trial_output_hidden_nonlinearities\": [], \"pad_zeros\":0, \"last_step\": False\n",
    "        },\n",
    "    },\n",
    "    \"rt_weight\": 0.01, # weight for the RT loss. \n",
    "    \"device\": \"cuda\", \n",
    "    # \"scheduler\": { # highly optional\n",
    "    #     \"name\": \"ReduceLROnPlateau\",\n",
    "    #     \"params\": {\n",
    "    #         \"mode\": \"min\",\n",
    "    #         \"factor\": 0.1,\n",
    "    #         \"patience\": 100,\n",
    "    #         \"min_lr\": 5e-4,\n",
    "    #         \"cooldown\": 50, \n",
    "    #     },\n",
    "    # }, \n",
    "    \"optimizer_specs\":{\n",
    "        \"optimizer_name\": \"Adam\",\n",
    "        \"optimizer_params\": {\n",
    "            \"lr\": 0.0005,\n",
    "        },\n",
    "    },\n",
    "    \"training_config\":{\n",
    "        \"task_id\": \"1.1\", # as opposed to \"Task-DyVA\". You may additionally put in later datasets here to convert to RT datasets.\n",
    "        \"task_config\": {\n",
    "            \"task\": \"PRL_Bartolo\",\n",
    "        }\n",
    "    },  \n",
    "    \"save_path\": MODEL_SAVE_PATH ,\n",
    "    \"check_path\": MODEL_SAVE_PATH,\n",
    "    \"log_path\": LOG_PATH, # These are to be modified when the big configs gets defined\n",
    "}\n",
    "\n",
    "for agent in [\"MB0s\"]:#, \"LS0\", \"MB0\", \"MB1\"]:\n",
    "    RTRNN_config[\"cog_data\"] = SIM_SAVE_PATH / 'simulated_Akam_RTS' / f'{agent}_seed0.pkl'\n",
    "    experiment = c.CustomMapper(RTRNN_config) # the RT is added right away. \n",
    "    experiment.rt_model = \"RELOAD\"\n",
    "    pickle.dump(experiment, open(DATA_PATH/f\"experiment_{agent}_1.pkl\", \"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876c1384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the thing like this: \n",
    "agent = \"MB0s\" # This is from cognitive models. \n",
    "try: \n",
    "    experiment = pickle.load(open(DATA_PATH/f\"experiment_{agent}_1.pkl\", \"rb\"))\n",
    "    experiment.initialise_dataloaders()\n",
    "    experiment.configs[\"model_specs\"][\"model_params\"][\"batch_size\"] = 64\n",
    "    experiment.initialise_trainer(experiment.configs)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Experiment for {agent} not found. Please run the simulation first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fdee6e",
   "metadata": {},
   "source": [
    "# Step 2: Train the most general form of RTRNNs\n",
    "see below for example codes to block train some base models for each agent type - for each model try: \n",
    "GRU hidden size 8, 16\n",
    "recurrence_per_trial: 1, 2, 3\n",
    "zero padding, 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceabeb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for agent in [\"MB0s\", \"LS0\", \"MB0\", \"MB1\"]:\n",
    "#     for hidden_size in [8, 16]:\n",
    "#         for zero_padding in [0, 1]:\n",
    "#             for recurrence_per_trial in [1, 2]: \n",
    "#                 experiment = pickle.load(open(DATA_PATH/f\"experiment_{agent}_1.pkl\", \"rb\"))\n",
    "#                 experiment.configs[\"model_specs\"][\"model_params\"][\"hidden_size\"] = hidden_size\n",
    "#                 experiment.configs[\"model_specs\"][\"model_params\"][\"pad_zeros\"] = zero_padding\n",
    "#                 experiment.configs[\"model_specs\"][\"model_params\"][\"recurrence_per_trial\"] = recurrence_per_trial\n",
    "#                 experiment.initialise_dataloaders()\n",
    "#                 experiment.initialise_trainer(experiment.configs)\n",
    "#                 model_name = f\"{agent}_GRU_HS={hidden_size}_N={recurrence_per_trial}_ZP{zero_padding}\"\n",
    "#                 for path in [experiment.configs[\"save_path\"], experiment.configs[\"check_path\"], experiment.configs[\"log_path\"]]:\n",
    "#                     path = path / model_name \n",
    "#                     if not os.path.exists(path):\n",
    "#                         os.makedirs(path)\n",
    "#                 experiment.trainer.train(\n",
    "#                     experiment.dataloaders[\"train\"],\n",
    "#                     experiment.dataloaders[\"val\"],\n",
    "#                     epochs = 2000,\n",
    "#                     save_interval = 500,\n",
    "#                     reset_interval = 10000,\n",
    "#                     save_path = experiment.configs[\"save_path\"] / model_name / \"model.pth\",\n",
    "#                     check_path = experiment.configs[\"check_path\"] / model_name,\n",
    "#                     log_path = experiment.configs[\"log_path\"] / model_name,\n",
    "#                     early_stop = 1000,\n",
    "#                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84a46c5",
   "metadata": {},
   "source": [
    "if you tried training as above, you can load your stuff to visualize as follows to compare model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4af0519",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = \"LS0\"\n",
    "experiment = pickle.load(open(DATA_PATH/f\"experiment_{agent}_0.pkl\", \"rb\"))\n",
    "hidden = 16\n",
    "recurrence = 1\n",
    "zero_padding = 1\n",
    "experiment.configs[\"model_specs\"][\"model_params\"][\"hidden_size\"] = hidden\n",
    "experiment.configs[\"model_specs\"][\"model_params\"][\"pad_zeros\"] = zero_padding\n",
    "experiment.configs[\"model_specs\"][\"model_params\"][\"recurrence_per_trial\"] = recurrence\n",
    "experiment.initialise_trainer(experiment.configs)\n",
    "experiment.trainer.load_model(experiment.configs[\"save_path\"]/\n",
    "                                f\"{agent}_RNN_HS={hidden_size}_N={recurrence}_ZP{zero_padding}_experimental_5\" / \"model.pth\")\n",
    "# plot boxplots, though each key from the dictionary has a different length\n",
    "rt_performance = pd.DataFrame(rt_performance)\n",
    "choice_performance = pd.DataFrame(choice_performance)\n",
    "# plot boxplots with sns\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(2, 1, figsize = (10, 10))\n",
    "sns.boxplot(data = np.log(rt_performance), ax = ax[0])\n",
    "ax[0].set_xticks(ticks = np.arange(len(rt_performance.columns)),\n",
    "                 labels = rt_performance.columns, rotation=45)\n",
    "ax[0].set_title(\"RT performance of models\")\n",
    "sns.boxplot(data = np.log(choice_performance), ax = ax[1])\n",
    "ax[1].set_xticks(ticks = np.arange(len(rt_performance.columns)),\n",
    "                 labels = rt_performance.columns, rotation=45)\n",
    "ax[1].set_title(\"Choice performance of models\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc0a165",
   "metadata": {},
   "source": [
    "# Step 3: Other RNN models: RTified and Discretised\n",
    "\n",
    "As mentioned earlier above, I did not persist in using the CustomMapper for everything. Hence in the following examples I show the alternative workflow. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8721a979",
   "metadata": {},
   "source": [
    "## 3.1. RTified\n",
    "\n",
    "The full notebook here is [[RNN_RT.ipynb]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85823301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Network_models.RTRNN import RTSlowFastRNN\n",
    "from Network_models.Trainer import SlowFastTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8c51f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RTRNN training on the data!\n",
    "batch_size = 64\n",
    "steps = 4\n",
    "identity_proj = False\n",
    "configs = {\n",
    "    \"save_path\": MODEL_SAVE_PATH / \"slow_fast\",\n",
    "    \"check_path\": MODEL_SAVE_PATH / \"slow_fast\",\n",
    "    \"log_path\": LOG_PATH / \"slow_fast\",\n",
    "    \"optimizer_specs\":{\n",
    "        \"optimizer_name\": \"Adam\",\n",
    "        \"optimizer_params\": {\n",
    "            \"lr\": 0.001,\n",
    "        },\n",
    "    },\n",
    "    \"model_specs\":{\n",
    "        \"model_name\": \"RTSlowFastRNN\", \n",
    "        \"model_path\": \"Network_models.RTRNN\",\n",
    "        \"model_params\":{\n",
    "            \"input_size\": 6, \"n_classes\": 2, \"h_slow_dim\": 16, \"h_fast_dim\": 16, \"fast_steps\": steps, \"identity_proj\": identity_proj,\n",
    "            \"trial_output_hidden\": 1, \"trial_output_hidden_size\": [16,], # if want hidden output layers (deep output, then give a list)\n",
    "            \"trial_output_hidden_nonlinearities\": [\"ReLU\"], \n",
    "        },\n",
    "    },\n",
    "    \"SFloss_specs\": {\n",
    "        \"rt_weight\": 0.5,  # weight for the RT loss\n",
    "    }, \n",
    "\n",
    "    \"device\": \"cuda\", \n",
    "    # \"scheduler\": {\n",
    "    #     \"name\": \"ReduceLROnPlateau\",\n",
    "    #     \"params\": {\n",
    "    #         \"mode\": \"min\",\n",
    "    #         \"factor\": 0.1,\n",
    "    #         \"patience\": 100,\n",
    "    #         \"min_lr\": 5e-4,\n",
    "    #         \"cooldown\": 50, \n",
    "    #     },\n",
    "    # }, \n",
    "    \"training_config\": {\n",
    "        \"batch_size\": 256, \n",
    "        \"val_ratio\": 0.2, \n",
    "        \"n_trials\": 10, \n",
    "    }, \n",
    "}\n",
    "\n",
    "# make the dirs\n",
    "for path in [configs[\"save_path\"], configs[\"check_path\"], configs[\"log_path\"]]:\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "rtrnn_trainer = SlowFastTrainer(configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4853bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'experiment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m dataloaders \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mexperiment\u001b[49m\u001b[38;5;241m.\u001b[39mdataloaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdataset,batch_size \u001b[38;5;241m=\u001b[39m batch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,)\n\u001b[1;32m      4\u001b[0m         \n\u001b[1;32m      5\u001b[0m     , \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m      6\u001b[0m         experiment\u001b[38;5;241m.\u001b[39mdataloaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdataset, batch_size \u001b[38;5;241m=\u001b[39m batch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m         )\n\u001b[1;32m      8\u001b[0m     }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'experiment' is not defined"
     ]
    }
   ],
   "source": [
    "dataloaders = {\n",
    "    \"train\": torch.utils.data.DataLoader(\n",
    "        experiment.dataloaders[\"train\"].dataset,batch_size = batch_size, shuffle=True,)\n",
    "        \n",
    "    , \"val\": torch.utils.data.DataLoader(\n",
    "        experiment.dataloaders[\"val\"].dataset, batch_size = batch_size, shuffle=False,\n",
    "        )\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9e5d3d",
   "metadata": {},
   "source": [
    "for these models, I would train in a particular way. \n",
    "\n",
    "stage 0: no RT loss. \n",
    "stage 1: RT loss (train with frozen backbone to warm up the RT module, then unfreeze to fine-tune the cognitive model based on RT information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e83d54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtrnn_trainer.train_loop(dataloaders[\"train\"], dataloaders[\"val\"], stage = 0, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75943a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtrnn_trainer.model.freeze_slow()\n",
    "rtrnn_trainer.train_loop(dataloaders[\"train\"], dataloaders[\"val\"], stage = 1, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e033662",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtrnn_trainer.model.unfreeze_slow()\n",
    "rtrnn_trainer.train_loop(dataloaders[\"train\"], dataloaders[\"val\"], stage = 1, epochs = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5946544b",
   "metadata": {},
   "source": [
    "## 3.2 Discretised RT\n",
    "\n",
    "The full notebook here is [[RNN_RT_discretised.ipynb]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec33300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Network_models.Trainer import DiscretisedTrainer\n",
    "\n",
    "# RTRNN training on the data!\n",
    "batch_size = 64\n",
    "reward_presentation_time = 0.5\n",
    "fixation_time = 0.5\n",
    "\n",
    "# knobs on the computation specs\n",
    "rsdf = 0 # repeat stim during fixation (default is to present during reward)\n",
    "rsda = 0 # repeat stim during action\n",
    "one_hot_input = True\n",
    "train_h0 = False # set to random initial condition to train the grounding fixed point structure during fixation\n",
    "\n",
    "dt = 0.1\n",
    "action_time = 1.5\n",
    "sigma_action = 0.1 # to smooth the action trains - potentially ease training  \n",
    "pad_ones = 1\n",
    "\n",
    "configs = {\n",
    "    \"save_path\": MODEL_SAVE_PATH / f\"discretised{'_pad_ones' if pad_ones else ''}\",\n",
    "    \"check_path\": MODEL_SAVE_PATH / f\"discretised{'_pad_ones' if pad_ones else ''}\",\n",
    "    \"log_path\": LOG_PATH / f\"discretised{'_pad_ones' if pad_ones else ''}\",\n",
    "    \"loss_type\": \"ce\", \n",
    "    \"optimizer_specs\":{\n",
    "        \"optimizer_name\": \"Adam\",\n",
    "        \"optimizer_params\": {\n",
    "            \"lr\": 0.001,\n",
    "        },\n",
    "    },\n",
    "    \"model_specs\":{\n",
    "        \"model_name\": \"RTDiscretisedRNN\", \n",
    "        \"model_path\": \"Network_models.RTRNN\",\n",
    "        \"model_params\":{\n",
    "            \"reward_presentation_time\": reward_presentation_time, \"repeat_stimulus_during_fixation\": rsdf,\n",
    "            \"repeat_stimulus_during_action\": rsda,\n",
    "            \"fixation_time\": fixation_time, \"action_time\": action_time, \n",
    "            \"one_hot_input\": one_hot_input, \"output_size\": 3, \"dt\": dt, \n",
    "            \"hidden_size\": 256, \"trial_output_hidden\": 1, \n",
    "            \"hidden_dimensions\": [64, ], \n",
    "            \"hidden_nonlinearities\": [\"ReLU\", ], \n",
    "            \"train_h0\": train_h0, \n",
    "            \"sigma_action\": sigma_action, \"batch_size\": batch_size, \"pad_ones\": pad_ones,\n",
    "        },\n",
    "    },\n",
    "    \"SFloss_specs\": {\n",
    "        \"rt_weight\": 0.5,  # weight for the RT loss\n",
    "    }, \n",
    "\n",
    "    \"device\": \"cuda\", \n",
    "    # \"scheduler\": False, \n",
    "    \"scheduler\": {\n",
    "        \"name\": \"ReduceLROnPlateau\",\n",
    "        \"params\": {\n",
    "            \"mode\": \"min\",\n",
    "            \"factor\": 0.1,\n",
    "            \"patience\": 100,\n",
    "            \"min_lr\": 5e-4,\n",
    "            \"cooldown\": 50, \n",
    "        },\n",
    "    }, \n",
    "    \"training_config\": {\n",
    "        \"batch_size\": batch_size, \n",
    "        \"val_ratio\": 0.2, \n",
    "        \"n_trials\": 10, \n",
    "    }, \n",
    "}\n",
    "\n",
    "# make the dirs\n",
    "for path in [configs[\"save_path\"], configs[\"check_path\"], configs[\"log_path\"]]:\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "rtrnn_trainer = DiscretisedTrainer(configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1196df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The trainer is implemented with a convert_dataset function to go from a cognitive dataset to fully discretised.\n",
    "# NOTE if you want to revive the CustomMapper, I recommend that you move this functionality over to the CustomMapper class. \n",
    "\n",
    "u_train, x_train = rtrnn_trainer.model.convert_dataset(dataloaders['train'].dataset.u, dataloaders['train'].dataset.x)\n",
    "u_val, x_val = rtrnn_trainer.model.convert_dataset(dataloaders['val'].dataset.u, dataloaders['val'].dataset.x)\n",
    "train_dataset = c.CustomDataset(u = u_train, x = x_train, device = rtrnn_trainer.model.device)\n",
    "val_dataset = c.CustomDataset(u = u_val, x = x_val, device = rtrnn_trainer.model.device)\n",
    "train_loader = DataLoader(train_dataset, batch_size=configs[\"training_config\"][\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=configs[\"training_config\"][\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac91c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "rtrnn_trainer.train_loop(train_loader, val_loader, epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe54837",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtrnn_trainer.load_checkpoint(rtrnn_trainer.check_path / \"best_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71acbc7d",
   "metadata": {},
   "source": [
    "For visualization of results &c. go to the expanded notebook. Just basic PCAs and stuff - you can do it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011752ef",
   "metadata": {},
   "source": [
    "# Step 4: HMM models\n",
    "\n",
    "The full notebook here is [[sim2test.ipynb]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e081ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = copy.deepcopy(dataloaders[\"train\"].dataset.x)\n",
    "\n",
    "dt = 0.5\n",
    "x[:, :, 1] = x[:, :, 1] * 1.5 * (x[:, :, 1] > 0) + x[:, :, 1] * (-1.5) * (x[:, :, 1] < 0)\n",
    "hmm_data = PaddedRTSeriesDataset(\n",
    "    u=dataloaders[\"train\"].dataset.u[0:100], \n",
    "    x=x[0:100],\n",
    "    dt=dt,\n",
    "    rt_ceiling=1.5,\n",
    "    keep_onehot=True,\n",
    ")\n",
    "hmm_loader = torch.utils.data.DataLoader(\n",
    "    hmm_data,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    ")\n",
    "x_val = copy.deepcopy(dataloaders[\"val\"].dataset.x)\n",
    "x_val[:, :, 1] = x_val[:, :, 1] * 1.5 * (x_val[:, :, 1] > 0) + x_val[:, :, 1] * (-1.5) * (x_val[:, :, 1] < 0)\n",
    "hmm_data_val = PaddedRTSeriesDataset(\n",
    "    u=dataloaders[\"val\"].dataset.u,\n",
    "    x=x_val,\n",
    "    dt=dt,\n",
    "    rt_ceiling=1.5,\n",
    "    keep_onehot=True,\n",
    ")\n",
    "hmm_loader_val = torch.utils.data.DataLoader(\n",
    "    hmm_data_val,\n",
    "    batch_size=200,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4c57cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Network_models.HMMModels import HMMModel_linearK\n",
    "K = 8\n",
    "stim_bits = 3\n",
    "model = HMMModel_linearK(z_dim = K, stim_types=stim_bits, symmetric=True)\n",
    "# model.load_checkpoint(MODEL_SAVE_PATH / \"HMMModel_linearK\" / \"best_epoch_no_rt.pth\")\n",
    "model.get_params()\n",
    "model.to(\"cuda\")\n",
    "ll_seq = []\n",
    "epochs = 16\n",
    "best_ll = -np.inf\n",
    "model.train()\n",
    "for epoch in range(epochs): \n",
    "    ll_loc = torch.zeros(len(hmm_loader))\n",
    "\n",
    "    for i, train_set in enumerate(hmm_loader):\n",
    "        recording = train_set[\"recording\"].to(\"cuda\")\n",
    "        stim_type = train_set[\"stimulus_type\"].to(\"cuda\")\n",
    "        mask = train_set[\"mask\"].to(\"cuda\")\n",
    "        \n",
    "        ll = model.fit_batch(stim_type, recording, mask.long())\n",
    "        print(f\"train_set {i+1}/{len(hmm_loader)}, log-lik={ll.mean().item():.3f}\")\n",
    "        if ll.mean().item() > best_ll: \n",
    "            best_ll = ll.mean().item()\n",
    "            model.save_checkpoint(MODEL_SAVE_PATH / \"HMMModel_linearK\" / f\"best_epoch.pth\")\n",
    " \n",
    "        ll_loc[i] = ll.mean().item()\n",
    "    ll_seq.append(ll_loc.mean().item())\n",
    "   \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, log-lik={ll_loc.mean().item():.3f}\")\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fd0dc4",
   "metadata": {},
   "source": [
    "NOTE: to figure out which stim is assigned to what, go to the figures in the expanded notebook! There is also a cool nx based visualization of the transition matrix. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNN_new",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
