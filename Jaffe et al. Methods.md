Practical log to re-create the method.

## High-level 

### Model Context

- generative model - similar to *Deep Variational Bayes Filters* (DVBF) 
- encoder model different from DVBF: 
	- in Task-DyVA, $\mathbf{w}_{t}$ depends on *current and future observations* (structure of the *true* posterior distribution)
	- DVBF: $\mathbf{w}_{t}$ depends on $\mathbf{x}_{t + 1}$ and $\mathbf{u}_{t}$ 
### Model Training

1. separation: 


